{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762ad838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 08:36:50.516063: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-18 08:36:50.525311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750228610.536240    1464 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750228610.539393    1464 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750228610.548361    1464 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750228610.548374    1464 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750228610.548375    1464 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750228610.548377    1464 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-18 08:36:50.551572: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:An interactive session is already active. This can cause out-of-memory errors or some other unexpected errors (due to the unpredictable timing of garbage collection) in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s). Please use `tf.Session()` if you intend to productionize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750228612.530289    1464 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6924 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1750228612.539205    1464 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6924 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config \n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "import mrcnn_code.egg as egg\n",
    "\n",
    "from mrcnn_code.egg import EggDataset, color_splash\n",
    "\n",
    "importlib.reload(modellib)\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"models\")\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \".weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a5132a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750228614.072696    1464 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6924 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "EGG_DIR = os.path.join(ROOT_DIR, \"Data/egg_annot\")\n",
    "config = egg.EggConfig()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "model.load_weights(MODEL_PATH, by_name=True)\n",
    "dataset_train = EggDataset()\n",
    "dataset_train.load_egg(EGG_DIR, \"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = EggDataset()\n",
    "dataset_val.load_egg(EGG_DIR, \"val\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca57cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/tibor/Documents/Python/mosquito-egg-identification/models/egg20250618T0836/.weights.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdataset_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mheads\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Python/mosquito-egg-identification/mrcnn/model.py:2417\u001b[39m, in \u001b[36mMaskRCNN.train\u001b[39m\u001b[34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[39m\n\u001b[32m   2415\u001b[39m log(\u001b[33m\"\u001b[39m\u001b[33mCheckpoint Path: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.checkpoint_path))\n\u001b[32m   2416\u001b[39m \u001b[38;5;28mself\u001b[39m.set_trainable(layers)\n\u001b[32m-> \u001b[39m\u001b[32m2417\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLEARNING_MOMENTUM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2419\u001b[39m \u001b[38;5;66;03m# Work-around for Windows: Keras fails on Windows when using\u001b[39;00m\n\u001b[32m   2420\u001b[39m \u001b[38;5;66;03m# multiprocessing workers. See discussion here:\u001b[39;00m\n\u001b[32m   2421\u001b[39m \u001b[38;5;66;03m# https://github.com/matterport/Mask_RCNN/issues/13#issuecomment-353124009\u001b[39;00m\n\u001b[32m   2422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.name == \u001b[33m'\u001b[39m\u001b[33mnt\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Python/mosquito-egg-identification/mrcnn/model.py:2261\u001b[39m, in \u001b[36mMaskRCNN.compile\u001b[39m\u001b[34m(self, learning_rate, momentum)\u001b[39m\n\u001b[32m   2258\u001b[39m loss_layer = \u001b[38;5;28mself\u001b[39m.keras_model.get_layer(name)\n\u001b[32m   2259\u001b[39m weight = \u001b[38;5;28mself\u001b[39m.config.LOSS_WEIGHTS.get(name, \u001b[32m1.0\u001b[39m)\n\u001b[32m   2260\u001b[39m \u001b[38;5;28mself\u001b[39m.keras_model.add_metric(\n\u001b[32m-> \u001b[39m\u001b[32m2261\u001b[39m     \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m * weight,\n\u001b[32m   2262\u001b[39m     name=name,\n\u001b[32m   2263\u001b[39m     aggregation=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2264\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Python/mosquito-egg-identification/venv/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[39m, in \u001b[36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Python/mosquito-egg-identification/venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Python/mosquito-egg-identification/venv/lib/python3.12/site-packages/keras/src/backend/common/keras_tensor.py:156\u001b[39m, in \u001b[36mKerasTensor.__tf_tensor__\u001b[39m\u001b[34m(self, dtype, name)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mused when constructing Keras Functional models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand `keras.ops`). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    165\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    171\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    172\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    173\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    175\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    176\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train,\n",
    "            dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=20,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d01a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting layers to train\n"
     ]
    }
   ],
   "source": [
    "# Zuerst im Inferenz-Modus erstellen\n",
    "inference_config = egg.EggConfig()\n",
    "inference_config.NAME = \"egg_inference\"\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                         config=inference_config,\n",
    "                         model_dir=MODEL_DIR)\n",
    "\n",
    "# Dann auf Training umstellen\n",
    "model.keras_model.trainable = True\n",
    "model.set_trainable(layer_regex=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c29d1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ input_image\n",
      "✓ zero_padding2d_1\n",
      "✓ conv1\n",
      "✓ bn_conv1\n",
      "✓ activation_74\n",
      "✓ max_pooling2d_1\n",
      "✓ res2a_branch2a\n",
      "✓ bn2a_branch2a\n",
      "☐ activation_75 (not in COCO)\n",
      "✓ res2a_branch2b\n",
      "✓ bn2a_branch2b\n",
      "☐ activation_76 (not in COCO)\n",
      "✓ res2a_branch2c\n",
      "✓ res2a_branch1\n",
      "✓ bn2a_branch2c\n",
      "✓ bn2a_branch1\n",
      "✓ add_33\n",
      "✓ res2a_out\n",
      "✓ res2b_branch2a\n",
      "✓ bn2b_branch2a\n",
      "☐ activation_77 (not in COCO)\n",
      "✓ res2b_branch2b\n",
      "✓ bn2b_branch2b\n",
      "☐ activation_78 (not in COCO)\n",
      "✓ res2b_branch2c\n",
      "✓ bn2b_branch2c\n",
      "☐ add_34 (not in COCO)\n",
      "✓ res2b_out\n",
      "✓ res2c_branch2a\n",
      "✓ bn2c_branch2a\n",
      "☐ activation_79 (not in COCO)\n",
      "✓ res2c_branch2b\n",
      "✓ bn2c_branch2b\n",
      "☐ activation_80 (not in COCO)\n",
      "✓ res2c_branch2c\n",
      "✓ bn2c_branch2c\n",
      "☐ add_35 (not in COCO)\n",
      "✓ res2c_out\n",
      "✓ res3a_branch2a\n",
      "✓ bn3a_branch2a\n",
      "☐ activation_81 (not in COCO)\n",
      "✓ res3a_branch2b\n",
      "✓ bn3a_branch2b\n",
      "☐ activation_82 (not in COCO)\n",
      "✓ res3a_branch2c\n",
      "✓ res3a_branch1\n",
      "✓ bn3a_branch2c\n",
      "✓ bn3a_branch1\n",
      "☐ add_36 (not in COCO)\n",
      "✓ res3a_out\n",
      "✓ res3b_branch2a\n",
      "✓ bn3b_branch2a\n",
      "☐ activation_83 (not in COCO)\n",
      "✓ res3b_branch2b\n",
      "✓ bn3b_branch2b\n",
      "☐ activation_84 (not in COCO)\n",
      "✓ res3b_branch2c\n",
      "✓ bn3b_branch2c\n",
      "☐ add_37 (not in COCO)\n",
      "✓ res3b_out\n",
      "✓ res3c_branch2a\n",
      "✓ bn3c_branch2a\n",
      "☐ activation_85 (not in COCO)\n",
      "✓ res3c_branch2b\n",
      "✓ bn3c_branch2b\n",
      "☐ activation_86 (not in COCO)\n",
      "✓ res3c_branch2c\n",
      "✓ bn3c_branch2c\n",
      "☐ add_38 (not in COCO)\n",
      "✓ res3c_out\n",
      "✓ res3d_branch2a\n",
      "✓ bn3d_branch2a\n",
      "☐ activation_87 (not in COCO)\n",
      "✓ res3d_branch2b\n",
      "✓ bn3d_branch2b\n",
      "☐ activation_88 (not in COCO)\n",
      "✓ res3d_branch2c\n",
      "✓ bn3d_branch2c\n",
      "☐ add_39 (not in COCO)\n",
      "✓ res3d_out\n",
      "✓ res4a_branch2a\n",
      "✓ bn4a_branch2a\n",
      "☐ activation_89 (not in COCO)\n",
      "✓ res4a_branch2b\n",
      "✓ bn4a_branch2b\n",
      "☐ activation_90 (not in COCO)\n",
      "✓ res4a_branch2c\n",
      "✓ res4a_branch1\n",
      "✓ bn4a_branch2c\n",
      "✓ bn4a_branch1\n",
      "☐ add_40 (not in COCO)\n",
      "✓ res4a_out\n",
      "✓ res4b_branch2a\n",
      "✓ bn4b_branch2a\n",
      "☐ activation_91 (not in COCO)\n",
      "✓ res4b_branch2b\n",
      "✓ bn4b_branch2b\n",
      "☐ activation_92 (not in COCO)\n",
      "✓ res4b_branch2c\n",
      "✓ bn4b_branch2c\n",
      "☐ add_41 (not in COCO)\n",
      "✓ res4b_out\n",
      "✓ res4c_branch2a\n",
      "✓ bn4c_branch2a\n",
      "☐ activation_93 (not in COCO)\n",
      "✓ res4c_branch2b\n",
      "✓ bn4c_branch2b\n",
      "☐ activation_94 (not in COCO)\n",
      "✓ res4c_branch2c\n",
      "✓ bn4c_branch2c\n",
      "☐ add_42 (not in COCO)\n",
      "✓ res4c_out\n",
      "✓ res4d_branch2a\n",
      "✓ bn4d_branch2a\n",
      "☐ activation_95 (not in COCO)\n",
      "✓ res4d_branch2b\n",
      "✓ bn4d_branch2b\n",
      "☐ activation_96 (not in COCO)\n",
      "✓ res4d_branch2c\n",
      "✓ bn4d_branch2c\n",
      "☐ add_43 (not in COCO)\n",
      "✓ res4d_out\n",
      "✓ res4e_branch2a\n",
      "✓ bn4e_branch2a\n",
      "☐ activation_97 (not in COCO)\n",
      "✓ res4e_branch2b\n",
      "✓ bn4e_branch2b\n",
      "☐ activation_98 (not in COCO)\n",
      "✓ res4e_branch2c\n",
      "✓ bn4e_branch2c\n",
      "☐ add_44 (not in COCO)\n",
      "✓ res4e_out\n",
      "✓ res4f_branch2a\n",
      "✓ bn4f_branch2a\n",
      "☐ activation_99 (not in COCO)\n",
      "✓ res4f_branch2b\n",
      "✓ bn4f_branch2b\n",
      "☐ activation_100 (not in COCO)\n",
      "✓ res4f_branch2c\n",
      "✓ bn4f_branch2c\n",
      "☐ add_45 (not in COCO)\n",
      "✓ res4f_out\n",
      "✓ res4g_branch2a\n",
      "✓ bn4g_branch2a\n",
      "☐ activation_101 (not in COCO)\n",
      "✓ res4g_branch2b\n",
      "✓ bn4g_branch2b\n",
      "☐ activation_102 (not in COCO)\n",
      "✓ res4g_branch2c\n",
      "✓ bn4g_branch2c\n",
      "☐ add_46 (not in COCO)\n",
      "✓ res4g_out\n",
      "✓ res4h_branch2a\n",
      "✓ bn4h_branch2a\n",
      "☐ activation_103 (not in COCO)\n",
      "✓ res4h_branch2b\n",
      "✓ bn4h_branch2b\n",
      "☐ activation_104 (not in COCO)\n",
      "✓ res4h_branch2c\n",
      "✓ bn4h_branch2c\n",
      "☐ add_47 (not in COCO)\n",
      "✓ res4h_out\n",
      "✓ res4i_branch2a\n",
      "✓ bn4i_branch2a\n",
      "☐ activation_105 (not in COCO)\n",
      "✓ res4i_branch2b\n",
      "✓ bn4i_branch2b\n",
      "☐ activation_106 (not in COCO)\n",
      "✓ res4i_branch2c\n",
      "✓ bn4i_branch2c\n",
      "☐ add_48 (not in COCO)\n",
      "✓ res4i_out\n",
      "✓ res4j_branch2a\n",
      "✓ bn4j_branch2a\n",
      "☐ activation_107 (not in COCO)\n",
      "✓ res4j_branch2b\n",
      "✓ bn4j_branch2b\n",
      "☐ activation_108 (not in COCO)\n",
      "✓ res4j_branch2c\n",
      "✓ bn4j_branch2c\n",
      "☐ add_49 (not in COCO)\n",
      "✓ res4j_out\n",
      "✓ res4k_branch2a\n",
      "✓ bn4k_branch2a\n",
      "☐ activation_109 (not in COCO)\n",
      "✓ res4k_branch2b\n",
      "✓ bn4k_branch2b\n",
      "☐ activation_110 (not in COCO)\n",
      "✓ res4k_branch2c\n",
      "✓ bn4k_branch2c\n",
      "☐ add_50 (not in COCO)\n",
      "✓ res4k_out\n",
      "✓ res4l_branch2a\n",
      "✓ bn4l_branch2a\n",
      "☐ activation_111 (not in COCO)\n",
      "✓ res4l_branch2b\n",
      "✓ bn4l_branch2b\n",
      "☐ activation_112 (not in COCO)\n",
      "✓ res4l_branch2c\n",
      "✓ bn4l_branch2c\n",
      "☐ add_51 (not in COCO)\n",
      "✓ res4l_out\n",
      "✓ res4m_branch2a\n",
      "✓ bn4m_branch2a\n",
      "☐ activation_113 (not in COCO)\n",
      "✓ res4m_branch2b\n",
      "✓ bn4m_branch2b\n",
      "☐ activation_114 (not in COCO)\n",
      "✓ res4m_branch2c\n",
      "✓ bn4m_branch2c\n",
      "☐ add_52 (not in COCO)\n",
      "✓ res4m_out\n",
      "✓ res4n_branch2a\n",
      "✓ bn4n_branch2a\n",
      "☐ activation_115 (not in COCO)\n",
      "✓ res4n_branch2b\n",
      "✓ bn4n_branch2b\n",
      "☐ activation_116 (not in COCO)\n",
      "✓ res4n_branch2c\n",
      "✓ bn4n_branch2c\n",
      "☐ add_53 (not in COCO)\n",
      "✓ res4n_out\n",
      "✓ res4o_branch2a\n",
      "✓ bn4o_branch2a\n",
      "☐ activation_117 (not in COCO)\n",
      "✓ res4o_branch2b\n",
      "✓ bn4o_branch2b\n",
      "☐ activation_118 (not in COCO)\n",
      "✓ res4o_branch2c\n",
      "✓ bn4o_branch2c\n",
      "☐ add_54 (not in COCO)\n",
      "✓ res4o_out\n",
      "✓ res4p_branch2a\n",
      "✓ bn4p_branch2a\n",
      "☐ activation_119 (not in COCO)\n",
      "✓ res4p_branch2b\n",
      "✓ bn4p_branch2b\n",
      "☐ activation_120 (not in COCO)\n",
      "✓ res4p_branch2c\n",
      "✓ bn4p_branch2c\n",
      "☐ add_55 (not in COCO)\n",
      "✓ res4p_out\n",
      "✓ res4q_branch2a\n",
      "✓ bn4q_branch2a\n",
      "☐ activation_121 (not in COCO)\n",
      "✓ res4q_branch2b\n",
      "✓ bn4q_branch2b\n",
      "☐ activation_122 (not in COCO)\n",
      "✓ res4q_branch2c\n",
      "✓ bn4q_branch2c\n",
      "☐ add_56 (not in COCO)\n",
      "✓ res4q_out\n",
      "✓ res4r_branch2a\n",
      "✓ bn4r_branch2a\n",
      "☐ activation_123 (not in COCO)\n",
      "✓ res4r_branch2b\n",
      "✓ bn4r_branch2b\n",
      "☐ activation_124 (not in COCO)\n",
      "✓ res4r_branch2c\n",
      "✓ bn4r_branch2c\n",
      "☐ add_57 (not in COCO)\n",
      "✓ res4r_out\n",
      "✓ res4s_branch2a\n",
      "✓ bn4s_branch2a\n",
      "☐ activation_125 (not in COCO)\n",
      "✓ res4s_branch2b\n",
      "✓ bn4s_branch2b\n",
      "☐ activation_126 (not in COCO)\n",
      "✓ res4s_branch2c\n",
      "✓ bn4s_branch2c\n",
      "☐ add_58 (not in COCO)\n",
      "✓ res4s_out\n",
      "✓ res4t_branch2a\n",
      "✓ bn4t_branch2a\n",
      "☐ activation_127 (not in COCO)\n",
      "✓ res4t_branch2b\n",
      "✓ bn4t_branch2b\n",
      "☐ activation_128 (not in COCO)\n",
      "✓ res4t_branch2c\n",
      "✓ bn4t_branch2c\n",
      "☐ add_59 (not in COCO)\n",
      "✓ res4t_out\n",
      "✓ res4u_branch2a\n",
      "✓ bn4u_branch2a\n",
      "☐ activation_129 (not in COCO)\n",
      "✓ res4u_branch2b\n",
      "✓ bn4u_branch2b\n",
      "☐ activation_130 (not in COCO)\n",
      "✓ res4u_branch2c\n",
      "✓ bn4u_branch2c\n",
      "☐ add_60 (not in COCO)\n",
      "✓ res4u_out\n",
      "✓ res4v_branch2a\n",
      "✓ bn4v_branch2a\n",
      "☐ activation_131 (not in COCO)\n",
      "✓ res4v_branch2b\n",
      "✓ bn4v_branch2b\n",
      "☐ activation_132 (not in COCO)\n",
      "✓ res4v_branch2c\n",
      "✓ bn4v_branch2c\n",
      "☐ add_61 (not in COCO)\n",
      "✓ res4v_out\n",
      "✓ res4w_branch2a\n",
      "✓ bn4w_branch2a\n",
      "☐ activation_133 (not in COCO)\n",
      "✓ res4w_branch2b\n",
      "✓ bn4w_branch2b\n",
      "☐ activation_134 (not in COCO)\n",
      "✓ res4w_branch2c\n",
      "✓ bn4w_branch2c\n",
      "☐ add_62 (not in COCO)\n",
      "✓ res4w_out\n",
      "✓ res5a_branch2a\n",
      "✓ bn5a_branch2a\n",
      "☐ activation_135 (not in COCO)\n",
      "✓ res5a_branch2b\n",
      "✓ bn5a_branch2b\n",
      "☐ activation_136 (not in COCO)\n",
      "✓ res5a_branch2c\n",
      "✓ res5a_branch1\n",
      "✓ bn5a_branch2c\n",
      "✓ bn5a_branch1\n",
      "☐ add_63 (not in COCO)\n",
      "✓ res5a_out\n",
      "✓ res5b_branch2a\n",
      "✓ bn5b_branch2a\n",
      "☐ activation_137 (not in COCO)\n",
      "✓ res5b_branch2b\n",
      "✓ bn5b_branch2b\n",
      "☐ activation_138 (not in COCO)\n",
      "✓ res5b_branch2c\n",
      "✓ bn5b_branch2c\n",
      "☐ add_64 (not in COCO)\n",
      "✓ res5b_out\n",
      "✓ res5c_branch2a\n",
      "✓ bn5c_branch2a\n",
      "☐ activation_139 (not in COCO)\n",
      "✓ res5c_branch2b\n",
      "✓ bn5c_branch2b\n",
      "☐ activation_140 (not in COCO)\n",
      "✓ res5c_branch2c\n",
      "✓ bn5c_branch2c\n",
      "☐ add_65 (not in COCO)\n",
      "✓ res5c_out\n",
      "✓ fpn_c5p5\n",
      "✓ fpn_p5upsampled\n",
      "✓ fpn_c4p4\n",
      "✓ fpn_p4add\n",
      "✓ fpn_p4upsampled\n",
      "✓ fpn_c3p3\n",
      "✓ fpn_p3add\n",
      "✓ fpn_p3upsampled\n",
      "✓ fpn_c2p2\n",
      "✓ fpn_p2add\n",
      "✓ fpn_p5\n",
      "✓ fpn_p2\n",
      "✓ fpn_p3\n",
      "✓ fpn_p4\n",
      "✓ fpn_p6\n",
      "✓ rpn_model\n",
      "✓ rpn_class\n",
      "✓ rpn_bbox\n",
      "☐ input_anchors (not in COCO)\n",
      "✓ ROI\n",
      "✓ input_image_meta\n",
      "✓ roi_align_classifier\n",
      "✓ mrcnn_class_conv1 (transferred despite shape difference)\n",
      "✓ mrcnn_class_bn1 (transferred despite shape difference)\n",
      "☐ activation_141 (not in COCO)\n",
      "✓ mrcnn_class_conv2 (transferred despite shape difference)\n",
      "✓ mrcnn_class_bn2 (transferred despite shape difference)\n",
      "☐ activation_142 (not in COCO)\n",
      "✓ pool_squeeze\n",
      "⚠ mrcnn_class_logits error: Layer mrcnn_class_logits weight shape (1024, 3) is not compatible with provided weight shape (3, 81).\n",
      "✗ mrcnn_bbox_fc (shape mismatch)\n",
      "✓ mrcnn_class\n",
      "✓ mrcnn_bbox\n",
      "☐ mrcnn_detection (not in COCO)\n",
      "☐ lambda_5 (not in COCO)\n",
      "✓ roi_align_mask\n",
      "✓ mrcnn_mask_conv1 (transferred despite shape difference)\n",
      "✓ mrcnn_mask_bn1 (transferred despite shape difference)\n",
      "☐ activation_144 (not in COCO)\n",
      "✓ mrcnn_mask_conv2 (transferred despite shape difference)\n",
      "✓ mrcnn_mask_bn2 (transferred despite shape difference)\n",
      "☐ activation_145 (not in COCO)\n",
      "✓ mrcnn_mask_conv3 (transferred despite shape difference)\n",
      "✓ mrcnn_mask_bn3 (transferred despite shape difference)\n",
      "☐ activation_146 (not in COCO)\n",
      "✓ mrcnn_mask_conv4 (transferred despite shape difference)\n",
      "✓ mrcnn_mask_bn4 (transferred despite shape difference)\n",
      "☐ activation_147 (not in COCO)\n",
      "✓ mrcnn_mask_deconv\n",
      "✗ mrcnn_mask (shape mismatch)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from mrcnn.model import ProposalLayer, PyramidROIAlign  # Import der Custom Layers\n",
    "\n",
    "COCO_MODEL_PATH = os.path.join(MODEL_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "def load_coco_weights_with_mismatch(model, coco_path):\n",
    "    # Layer, die trotz Shape-Unterschied übertragen werden können\n",
    "    TRANSFERABLE_LAYERS = [\n",
    "        'mrcnn_class_conv1', 'mrcnn_class_bn1',\n",
    "        'mrcnn_class_conv2', 'mrcnn_class_bn2',\n",
    "        'mrcnn_mask_conv1', 'mrcnn_mask_bn1',\n",
    "        'mrcnn_mask_conv2', 'mrcnn_mask_bn2',\n",
    "        'mrcnn_mask_conv3', 'mrcnn_mask_bn3',\n",
    "        'mrcnn_mask_conv4', 'mrcnn_mask_bn4'\n",
    "    ]\n",
    "    \n",
    "    with h5py.File(coco_path, 'r') as f:\n",
    "        layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n",
    "        \n",
    "        for layer in model.keras_model.layers:\n",
    "            if layer.name in layer_names:\n",
    "                try:\n",
    "                    g = f[layer.name]\n",
    "                    weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n",
    "                    weights = [np.array(g[wn]) for wn in weight_names]\n",
    "                    \n",
    "                    # Spezialbehandlung für bestimmte Layer\n",
    "                    if layer.name in TRANSFERABLE_LAYERS:\n",
    "                        print(f\"✓ {layer.name} (transferred despite shape difference)\")\n",
    "                        layer.set_weights(weights)\n",
    "                    elif layer.name == 'mrcnn_class_logits':\n",
    "                        # Nur die ersten N Gewichte übertragen\n",
    "                        new_weights = [w[:model.config.NUM_CLASSES] if w.ndim > 0 else w for w in weights]\n",
    "                        layer.set_weights(new_weights)\n",
    "                        print(f\"✓ {layer.name} (partial transfer)\")\n",
    "                    else:\n",
    "                        if [w.shape for w in weights] == [w.shape for w in layer.get_weights()]:\n",
    "                            layer.set_weights(weights)\n",
    "                            print(f\"✓ {layer.name}\")\n",
    "                        else:\n",
    "                            print(f\"✗ {layer.name} (shape mismatch)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠ {layer.name} error: {str(e)}\")\n",
    "            else:\n",
    "                print(f\"☐ {layer.name} (not in COCO)\")\n",
    "\n",
    "# Verwendung:\n",
    "load_coco_weights_with_mismatch(model, COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "403e1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keras_model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20ef782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keras_model.save_weights('.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222420fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting layers to train\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "Selecting layers to train\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "Selecting layers to train\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Selecting layers to train\n",
      "Selecting layers to train\n"
     ]
    }
   ],
   "source": [
    "layers_to_train = [\n",
    "    'mrcnn_class_logits',\n",
    "    'mrcnn_bbox_fc',\n",
    "    'mrcnn_mask',\n",
    "    'rpn_class',\n",
    "    'rpn_bbox'\n",
    "]\n",
    "\n",
    "# Für jeden Layer einzeln\n",
    "for layer_pattern in layers_to_train:\n",
    "    model.set_trainable(layer_pattern)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
