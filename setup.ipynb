{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f5edff",
   "metadata": {},
   "source": [
    "# Creating a napari-convpaint segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4344805\ttotal: 59.3ms\tremaining: 5.87s\n",
      "1:\tlearn: 0.2817036\ttotal: 66.9ms\tremaining: 3.28s\n",
      "2:\tlearn: 0.1774183\ttotal: 75ms\tremaining: 2.42s\n",
      "3:\tlearn: 0.1273576\ttotal: 82.6ms\tremaining: 1.98s\n",
      "4:\tlearn: 0.0807750\ttotal: 89.9ms\tremaining: 1.71s\n",
      "5:\tlearn: 0.0560956\ttotal: 98.3ms\tremaining: 1.54s\n",
      "6:\tlearn: 0.0452980\ttotal: 107ms\tremaining: 1.42s\n",
      "7:\tlearn: 0.0375513\ttotal: 114ms\tremaining: 1.31s\n",
      "8:\tlearn: 0.0315362\ttotal: 122ms\tremaining: 1.23s\n",
      "9:\tlearn: 0.0251572\ttotal: 130ms\tremaining: 1.17s\n",
      "10:\tlearn: 0.0222977\ttotal: 138ms\tremaining: 1.12s\n",
      "11:\tlearn: 0.0203142\ttotal: 146ms\tremaining: 1.07s\n",
      "12:\tlearn: 0.0182062\ttotal: 154ms\tremaining: 1.03s\n",
      "13:\tlearn: 0.0167104\ttotal: 162ms\tremaining: 996ms\n",
      "14:\tlearn: 0.0158393\ttotal: 171ms\tremaining: 969ms\n",
      "15:\tlearn: 0.0149588\ttotal: 179ms\tremaining: 940ms\n",
      "16:\tlearn: 0.0142842\ttotal: 187ms\tremaining: 911ms\n",
      "17:\tlearn: 0.0137138\ttotal: 194ms\tremaining: 884ms\n",
      "18:\tlearn: 0.0132466\ttotal: 202ms\tremaining: 861ms\n",
      "19:\tlearn: 0.0127415\ttotal: 210ms\tremaining: 840ms\n",
      "20:\tlearn: 0.0124881\ttotal: 218ms\tremaining: 822ms\n",
      "21:\tlearn: 0.0120698\ttotal: 225ms\tremaining: 799ms\n",
      "22:\tlearn: 0.0115099\ttotal: 233ms\tremaining: 781ms\n",
      "23:\tlearn: 0.0113098\ttotal: 241ms\tremaining: 763ms\n",
      "24:\tlearn: 0.0111462\ttotal: 247ms\tremaining: 741ms\n",
      "25:\tlearn: 0.0110237\ttotal: 253ms\tremaining: 721ms\n",
      "26:\tlearn: 0.0109504\ttotal: 261ms\tremaining: 706ms\n",
      "27:\tlearn: 0.0104802\ttotal: 269ms\tremaining: 692ms\n",
      "28:\tlearn: 0.0103820\ttotal: 277ms\tremaining: 679ms\n",
      "29:\tlearn: 0.0103361\ttotal: 287ms\tremaining: 671ms\n",
      "30:\tlearn: 0.0099764\ttotal: 300ms\tremaining: 667ms\n",
      "31:\tlearn: 0.0097165\ttotal: 308ms\tremaining: 654ms\n",
      "32:\tlearn: 0.0093124\ttotal: 317ms\tremaining: 644ms\n",
      "33:\tlearn: 0.0090320\ttotal: 326ms\tremaining: 632ms\n",
      "34:\tlearn: 0.0089917\ttotal: 334ms\tremaining: 621ms\n",
      "35:\tlearn: 0.0088185\ttotal: 342ms\tremaining: 609ms\n",
      "36:\tlearn: 0.0087631\ttotal: 350ms\tremaining: 595ms\n",
      "37:\tlearn: 0.0086853\ttotal: 357ms\tremaining: 582ms\n",
      "38:\tlearn: 0.0084579\ttotal: 364ms\tremaining: 570ms\n",
      "39:\tlearn: 0.0084045\ttotal: 370ms\tremaining: 555ms\n",
      "40:\tlearn: 0.0083395\ttotal: 376ms\tremaining: 542ms\n",
      "41:\tlearn: 0.0081130\ttotal: 386ms\tremaining: 533ms\n",
      "42:\tlearn: 0.0080787\ttotal: 394ms\tremaining: 522ms\n",
      "43:\tlearn: 0.0080330\ttotal: 402ms\tremaining: 511ms\n",
      "44:\tlearn: 0.0077248\ttotal: 409ms\tremaining: 500ms\n",
      "45:\tlearn: 0.0075726\ttotal: 416ms\tremaining: 488ms\n",
      "46:\tlearn: 0.0073735\ttotal: 423ms\tremaining: 477ms\n",
      "47:\tlearn: 0.0070750\ttotal: 431ms\tremaining: 467ms\n",
      "48:\tlearn: 0.0070446\ttotal: 439ms\tremaining: 457ms\n",
      "49:\tlearn: 0.0068675\ttotal: 447ms\tremaining: 447ms\n",
      "50:\tlearn: 0.0068280\ttotal: 454ms\tremaining: 436ms\n",
      "51:\tlearn: 0.0067033\ttotal: 462ms\tremaining: 427ms\n",
      "52:\tlearn: 0.0066629\ttotal: 469ms\tremaining: 416ms\n",
      "53:\tlearn: 0.0066138\ttotal: 479ms\tremaining: 408ms\n",
      "54:\tlearn: 0.0065502\ttotal: 486ms\tremaining: 398ms\n",
      "55:\tlearn: 0.0065042\ttotal: 498ms\tremaining: 391ms\n",
      "56:\tlearn: 0.0064863\ttotal: 505ms\tremaining: 381ms\n",
      "57:\tlearn: 0.0063569\ttotal: 512ms\tremaining: 371ms\n",
      "58:\tlearn: 0.0063102\ttotal: 519ms\tremaining: 361ms\n",
      "59:\tlearn: 0.0062628\ttotal: 526ms\tremaining: 351ms\n",
      "60:\tlearn: 0.0062312\ttotal: 535ms\tremaining: 342ms\n",
      "61:\tlearn: 0.0062145\ttotal: 540ms\tremaining: 331ms\n",
      "62:\tlearn: 0.0061327\ttotal: 548ms\tremaining: 322ms\n",
      "63:\tlearn: 0.0060735\ttotal: 554ms\tremaining: 312ms\n",
      "64:\tlearn: 0.0060124\ttotal: 562ms\tremaining: 302ms\n",
      "65:\tlearn: 0.0059858\ttotal: 569ms\tremaining: 293ms\n",
      "66:\tlearn: 0.0059167\ttotal: 577ms\tremaining: 284ms\n",
      "67:\tlearn: 0.0057927\ttotal: 584ms\tremaining: 275ms\n",
      "68:\tlearn: 0.0057669\ttotal: 591ms\tremaining: 266ms\n",
      "69:\tlearn: 0.0056317\ttotal: 600ms\tremaining: 257ms\n",
      "70:\tlearn: 0.0055688\ttotal: 609ms\tremaining: 249ms\n",
      "71:\tlearn: 0.0054350\ttotal: 618ms\tremaining: 240ms\n",
      "72:\tlearn: 0.0053980\ttotal: 624ms\tremaining: 231ms\n",
      "73:\tlearn: 0.0052837\ttotal: 631ms\tremaining: 222ms\n",
      "74:\tlearn: 0.0052399\ttotal: 638ms\tremaining: 213ms\n",
      "75:\tlearn: 0.0052009\ttotal: 646ms\tremaining: 204ms\n",
      "76:\tlearn: 0.0051643\ttotal: 653ms\tremaining: 195ms\n",
      "77:\tlearn: 0.0050773\ttotal: 669ms\tremaining: 189ms\n",
      "78:\tlearn: 0.0050450\ttotal: 678ms\tremaining: 180ms\n",
      "79:\tlearn: 0.0050275\ttotal: 692ms\tremaining: 173ms\n",
      "80:\tlearn: 0.0048885\ttotal: 703ms\tremaining: 165ms\n",
      "81:\tlearn: 0.0047382\ttotal: 711ms\tremaining: 156ms\n",
      "82:\tlearn: 0.0047040\ttotal: 718ms\tremaining: 147ms\n",
      "83:\tlearn: 0.0046886\ttotal: 726ms\tremaining: 138ms\n",
      "84:\tlearn: 0.0046485\ttotal: 734ms\tremaining: 129ms\n",
      "85:\tlearn: 0.0045758\ttotal: 742ms\tremaining: 121ms\n",
      "86:\tlearn: 0.0044816\ttotal: 749ms\tremaining: 112ms\n",
      "87:\tlearn: 0.0043725\ttotal: 757ms\tremaining: 103ms\n",
      "88:\tlearn: 0.0043377\ttotal: 764ms\tremaining: 94.4ms\n",
      "89:\tlearn: 0.0043047\ttotal: 771ms\tremaining: 85.7ms\n",
      "90:\tlearn: 0.0042816\ttotal: 777ms\tremaining: 76.9ms\n",
      "91:\tlearn: 0.0042536\ttotal: 784ms\tremaining: 68.2ms\n",
      "92:\tlearn: 0.0041858\ttotal: 792ms\tremaining: 59.6ms\n",
      "93:\tlearn: 0.0041269\ttotal: 800ms\tremaining: 51ms\n",
      "94:\tlearn: 0.0041198\ttotal: 807ms\tremaining: 42.5ms\n",
      "95:\tlearn: 0.0041005\ttotal: 814ms\tremaining: 33.9ms\n",
      "96:\tlearn: 0.0040162\ttotal: 823ms\tremaining: 25.5ms\n",
      "97:\tlearn: 0.0039309\ttotal: 831ms\tremaining: 17ms\n",
      "98:\tlearn: 0.0039137\ttotal: 837ms\tremaining: 8.46ms\n",
      "99:\tlearn: 0.0038133\ttotal: 845ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fe498949340>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "from napari_convpaint.conv_paint_model import ConvpaintModel\n",
    "\n",
    "image = skimage.io.imread(\"Data/microscope/aegypti/ag_06.tif\")\n",
    "annotations = skimage.io.imread(\"Data/annotations_ag_06.tif\")\n",
    "\n",
    "model = ConvpaintModel(\n",
    "    fe_name=\"efficient_netb0\",\n",
    "    fe_use_cuda=True,\n",
    "    fe_layers=[1],\n",
    "    fe_scalings=[1]\n",
    ")\n",
    "\n",
    "model.set_params(\n",
    "    image_downsample=1,\n",
    "    tile_annotations=True,\n",
    "    tile_image=True,\n",
    "    clf_iterations=100,\n",
    "    seg_smoothening=3\n",
    ")\n",
    "\n",
    "annotations = annotations.astype(np.uint8)\n",
    "\n",
    "model.train(image.transpose(2, 0, 1), annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db9471ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Enet_vx\"\n",
    "model.save(\"Models/\" + model_name + \".pkl\", create_yml=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122d244",
   "metadata": {},
   "source": [
    "# Testing a segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_convpaint.conv_paint_model import ConvpaintModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_name = \"Enet_v7\"\n",
    "image = skimage.io.imread('Data/microscope/aegypti/ag_07.tif')\n",
    "\n",
    "model = ConvpaintModel(\"Models/\" + model_name + \".pkl\")\n",
    "image = np.moveaxis(image, -1, 0)\n",
    "segment = model.segment(image)\n",
    "plt.imshow(segment, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4767a",
   "metadata": {},
   "source": [
    "# Segmenting a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83294e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes, dilation, footprint_rectangle, erosion\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "rec = 25\n",
    "\n",
    "mask_cleaned = remove_small_holes(segment == 2, area_threshold=5000)\n",
    "labeled_overlay = label(mask_cleaned)\n",
    "labeled_overlay = erosion(labeled_overlay, footprint=footprint_rectangle((rec, rec)))\n",
    "labeled_overlay = remove_small_objects(labeled_overlay, min_size=20000)\n",
    "labeled_overlay = dilation(labeled_overlay, footprint_rectangle((rec, rec)), mode='ignore')\n",
    "\n",
    "regions = regionprops(labeled_overlay)\n",
    "plt.imshow(labeled_overlay, cmap='gray')\n",
    "\n",
    "segmented_image = []\n",
    "\n",
    "for i, region in enumerate(regions):\n",
    "    # Bounding Box extrahieren\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "\n",
    "    # Ausschnitt des Bildes und der Maske\n",
    "    cropped_image = image[minr:maxr, minc:maxc]\n",
    "    mask = labeled_overlay[minr:maxr, minc:maxc] == region.label\n",
    "\n",
    "    # Maske anwenden (falls nötig, z. B. für transparente Bereiche)\n",
    "    masked_image = np.zeros_like(cropped_image)\n",
    "    for c in range(cropped_image.shape[2]):\n",
    "        masked_image[..., c] = cropped_image[..., c] * mask\n",
    "\n",
    "    segmented_image.append(masked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7962a5d",
   "metadata": {},
   "source": [
    "## Segmenting a lot of pictures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65254d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from skimage.measure import regionprops\n",
    "from skimage.morphology import remove_small_holes, remove_small_objects, dilation, footprint_rectangle\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "model = ConvpaintModel(model_path=\"Models/Enet_v7.pkl\")\n",
    "image_paths = glob.glob(\"Data/microscope/**/*.tif\", recursive=True)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "segments = []\n",
    "segmented_image = []\n",
    "data = []\n",
    "rec = 25\n",
    "\n",
    "for path in image_paths:\n",
    "    img = skimage.io.imread(path)\n",
    "    images.append(img)\n",
    "    labell = os.path.basename(os.path.dirname(path))\n",
    "    labels.append(labell)\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    segment = segmentation(image, model)\n",
    "    segments.append(segment)\n",
    "    mask_cleaned = remove_small_holes(segment == 2, area_threshold=5000)\n",
    "    labeled_overlay = label(mask_cleaned)\n",
    "    labeled_overlay = erosion(labeled_overlay, footprint=footprint_rectangle((rec, rec)))\n",
    "    labeled_overlay = remove_small_objects(labeled_overlay, min_size=20000)\n",
    "    labeled_overlay = dilation(labeled_overlay, footprint_rectangle((rec, rec)), mode='ignore')\n",
    "    regions = regionprops(labeled_overlay)\n",
    "    \n",
    "    for j, region in enumerate(regions):\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        cropped_image = image[minr:maxr, minc:maxc]\n",
    "        mask = labeled_overlay[minr:maxr, minc:maxc] == region.label\n",
    "        masked_image = np.zeros_like(cropped_image)\n",
    "        for c in range(cropped_image.shape[2]):\n",
    "            masked_image[..., c] = cropped_image[..., c] * mask\n",
    "        segmented_image.append(masked_image)\n",
    "        image_gray = skimage.color.rgb2gray(masked_image)\n",
    "\n",
    "        skimage.io.imsave(f\"Data/segmented_image/image{i}_segment_{j}.png\", img_as_ubyte(masked_image))\n",
    "        skimage.io.imsave(f\"Data/segmented_mask/mask{i}_segment_{j}.png\", img_as_ubyte(mask))\n",
    "\n",
    "        angle = region.orientation\n",
    "        area = region.area\n",
    "        perimeter = region.perimeter\n",
    "        roundness = 4 * np.pi * area / (perimeter ** 2) if perimeter != 0 else 0\n",
    "        length = region.axis_major_length\n",
    "        centroid = region.centroid\n",
    "        centroid_local = (centroid[0] - minr, centroid[1] - minc)\n",
    "        width = region.axis_minor_length\n",
    "        ratio = length / width\n",
    "        laplacian = measure_sharpness(image_gray)\n",
    "        edge = gradient_sharpness(image_gray)\n",
    "\n",
    "        data.append({\n",
    "            'image': i,\n",
    "            'segment': j,\n",
    "            'area': area,\n",
    "            'perimeter': perimeter,\n",
    "            'roundness': roundness,\n",
    "            'length': length,\n",
    "            'width': width,\n",
    "            'len_wid_ratio': ratio,\n",
    "            'laplacian' : laplacian,\n",
    "            'edge': edge\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c8fbf",
   "metadata": {},
   "source": [
    "# Creating a model for identifying and classifying segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fada98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 50, 100, 200, 500],\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "grid_search_forest = GridSearchCV(model, param_grid, cv=5, scoring='precision', n_jobs=-1, verbose=2)\n",
    "grid_search_forest.fit(X, y)\n",
    "best_forest_model = grid_search_forest.best_estimator_\n",
    "y_pred = best_forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72698352",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, y_pred, target_names=y.columns, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f5ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "combined_y_test = y_test.apply(lambda row: ''.join(row.astype(str)), axis=1)\n",
    "combined_y_pred = pd.DataFrame(y_pred, columns=y.columns).apply(lambda row: ''.join(row.astype(str)), axis=1)\n",
    "\n",
    "conf_matrix_combined = confusion_matrix(combined_y_test, combined_y_pred)\n",
    "\n",
    "labels_sorted = sorted(set(combined_y_test) | set(combined_y_pred))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix_combined, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels_sorted, yticklabels=labels_sorted)\n",
    "plt.xlabel(\"Vorhergesagte Label-Kombination\")\n",
    "plt.ylabel(\"Tatsächliche Label-Kombination\")\n",
    "plt.title(\"Multilabel Confusion Matrix (kombinierte Klassen)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(best_forest_model, 'Models/segmentation_identifier_random_forest.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "loaded_model = load('Models/segmentation_identifier_random_forest.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
